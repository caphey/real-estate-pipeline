# Pipeline de Donn√©es Financi√®res E2E

![Statut du Pipeline](https://github.com/caphey/real-estate-pipeline/actions/workflows/daily_pipeline.yml/badge.svg)

Ce projet est un pipeline de donn√©es **End-to-End (E-L-T)** complet.

L'objectif est de collecter quotidiennement des donn√©es boursi√®res depuis une API publique, de les stocker dans un Data Warehouse, de les transformer en mod√®les analytiques propres, et d'orchestrer ce flux de mani√®re fiable et automatis√©e.

## üèõÔ∏è Architecture du Pipeline

Ce projet suit une architecture E-L-T moderne orchestr√©e par un outil de CI/CD.

```
[GitHub Actions (Scheduler)]
       |
       v
[Python Script (Extract-Load)] ----------------> [API (Alpha Vantage)]
       | (Donn√©es brutes)
       v
[Docker: PostgreSQL (Sch√©ma: public)]
       |
       v
[dbt (Transform)]
       | (Mod√®les Staging & Marts)
       v
[Docker: PostgreSQL (Sch√©ma: dbt_analytics)]
       |
       v
[dbt (Test)] ---> (Alerte si √©chec)
```

## üõ†Ô∏è Stack Technique

* **Extraction & Chargement (E-L) :** **Python** (`requests`, `psycopg2`, `python-dotenv`)
* **Infrastructure (DWH) :** **PostgreSQL** (tournant sur **Docker**)
* **Infrastructure as Code (IaC) :** **Docker-Compose**
* **Transformation (T) :** **dbt (Data Build Tool)**
* **Orchestration & CI/CD :** **GitHub Actions**
* **Tests de Qualit√© :** **dbt test**

## ‚ú® Fonctionnalit√©s Cl√©s

* **Infrastructure Reproductible :** `docker-compose.yml` permet de lancer une base de donn√©es PostgreSQL identique en une seule commande (`docker-compose up`).
* **Tests de Qualit√© des Donn√©es :** Des tests `dbt` sont en place pour garantir la fiabilit√© des donn√©es (ex: `not_null`, `unique`, `accepted_values` et des tests singuliers comme `closing_price > 0`).
* **Orchestration Automatis√©e :** Le workflow GitHub Actions ex√©cute l'int√©gralit√© du pipeline (E-L puis T) tous les jours, et ex√©cute les tests pour valider la production.
* **Gestion des Secrets :** Les cl√©s d'API et mots de passe de BDD sont g√©r√©s de mani√®re s√©curis√©e via un fichier `.env` en local et les `GitHub Secrets` pour la production.
* **Documentation & Lignage :** Le projet dbt est document√©. Le lignage des donn√©es (de la source brute au "mart" final) peut √™tre visualis√© avec `dbt docs generate` & `dbt docs serve`.

## üöÄ Comment l'ex√©cuter en local

1.  **Cloner le d√©p√¥t :**
    ```bash
    git clone [https://github.com/](https://github.com/)caphey/real-estate-pipeline.git
    cd real-estate-pipeline
    ```

2.  **Pr√©requis :**
    * Avoir **Docker Desktop** install√© et lanc√©.
    * Avoir **Python 3.9+**.

3.  **Cr√©er les secrets :**
    Cr√©ez un fichier `.env` √† la racine du projet (sur la base de `.env.example`) et remplissez-le avec vos identifiants.
    ```bash
    # Exemple pour .env
    API_KEY=VOTRE_CLE_ALPHA_VANTAGE
    DB_USER=postgres
    DB_PASSWORD=realreal
    DB_NAME=stock_data
    ```

4.  **Lancer la Base de Donn√©es :**
    ```bash
    docker-compose up -d
    ```

5.  **Installer les d√©pendances Python :**
    (Il est recommand√© de cr√©er un environnement virtuel : `python -m venv venv`)
    ```bash
    pip install -r requirements.txt
    ```

6.  **Configurer le profil dbt :**
    `dbt` cherche son profil dans `~/.dbt/profiles.yml`. Assurez-vous d'avoir un profil pointant vers la base Docker. `dbt init` peut vous y aider.
    ```yaml
    # Exemple de ~/.dbt/profiles.yml
    dbt_stock_project:
      target: dev
      outputs:
        dev:
          type: postgres
          host: localhost
          port: 5432
          user: postgres       # Doit correspondre √† votre .env
          pass: realreal # Doit correspondre √† votre .env
          dbname: stock_data  # Doit correspondre √† votre .env
          schema: dbt_analytics
    ```

7.  **Ex√©cuter le pipeline manuellement :**

    * **√âtape E-L (Extract & Load) :**
        ```bash
        python src/extract_load.py
        ```

    * **√âtape T (Transform) :**
        ```bash
        dbt run --project-dir ./dbt_stock_project
        ```

    * **√âtape QA (Tests) :**
        ```bash
        dbt test --project-dir ./dbt_stock_project
        ```

8.  **Voir la Documentation :**
    ```bash
    dbt docs generate --project-dir ./dbt_stock_project
    dbt docs serve --project-dir ./dbt_stock_project
    ```
    Ouvrez ensuite `http://localhost:8080` dans votre navigateur.